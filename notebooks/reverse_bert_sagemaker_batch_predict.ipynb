{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Set  up  accounts and role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "from uuid import uuid4\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "account_id =  boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "\n",
    "#role = sagemaker.get_execution_role()\n",
    "role=\"arn:aws:iam::{}:role/service-role/AmazonSageMaker-ExecutionRole-20190118T115449\".format(account_id)\n",
    "max_runs=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Setup image and instance type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_custom_image_name=\"bertreverse:gpu-202201301844\"\n",
    "instance_type = \"ml.p3.2xlarge\"\n",
    "instance_type_gpu_map = {\"ml.p3.8xlarge\":4, \"ml.p3.2xlarge\": 1, \"ml.p3.16xlarge\":8}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_repo = \"{}.dkr.ecr.{}.amazonaws.com/{}\".format(account_id, region, pytorch_custom_image_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Configure train/ test and validation datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"aegovan-data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_input_vocab =\"s3://{}/embeddings/bert_base_cased/\".format(bucket)\n",
    "\n",
    "s3_input_data = \"s3://{}/mnli_dataset/val/multinli_1.0_dev_matched.jsonl\".format(bucket)\n",
    "\n",
    "s3_model_path= \"s3://{}/mnli_sagemakerresults/mnli-reverse-lang-bert-accuracy-2022-01-23-21-29-34-327/output/\".format(bucket)\n",
    "s3_code_path= \"s3://{}/mnli_bert_code\".format(bucket)\n",
    "s3_output_predictions = \"s3://{}/mnli_predictions\".format(bucket)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "commit 85ec10ff4f4f5eae6947caa0ebe85b99b6bbe996\n",
      "    Bug Fix - Model not found\n"
     ]
    }
   ],
   "source": [
    "!git log -1 | head -1\n",
    "!git log -1 | head -5 | tail -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set True if you need spot instance\n",
    "instance_count=1\n",
    "use_spot = False\n",
    "train_max_run_secs =   5 *24 * 60 * 60\n",
    "spot_wait_sec =  60 * 60 * 5\n",
    "max_wait_time_secs = train_max_run_secs +  spot_wait_sec\n",
    "\n",
    "if not use_spot:\n",
    "    max_wait_time_secs = None\n",
    "    \n",
    "# During local mode, no spot.., use smaller dataset\n",
    "if instance_type == 'local':\n",
    "    use_spot = False\n",
    "    max_wait_time_secs = 0\n",
    "    wait = True\n",
    "    instance_count=1\n",
    "    # Use smaller dataset to run locally\n",
    "    inputs = inputs_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_data_type=\"S3Prefix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  bert-reverse-inference-2022-01-30-18-52-52-271\n",
      "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/mnli_dataset/val/multinli_1.0_dev_matched.jsonl', 'LocalPath': '/opt/ml/processing/input/data/jsonlines', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-2', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/mnli_sagemakerresults/mnli-reverse-lang-bert-accuracy-2022-01-23-21-29-34-327/output/', 'LocalPath': '/opt/ml/processing/input/data/models', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'input-3', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://aegovan-data/embeddings/bert_base_cased/', 'LocalPath': '/opt/ml/processing/input/data/vocab', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-2-324346001917/bert-reverse-inference-2022-01-30-18-52-52-271/input/code/reverse_lang_mnli_batch_predict.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'predictions', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://aegovan-data/mnli_predictions', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n",
      "......................................\u001b[34m{'datajson': '/opt/ml/processing/input/data/jsonlines', 'artefactsdir': '/opt/ml/processing/input/data/models', 'outdir': '/opt/ml/processing/output', 'log_level': 'INFO', 'numworkers': None, 'batch': 32, 'ensemble': 0}\u001b[0m\n",
      "\u001b[34m{'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab', 'vocab_file': '/opt/ml/processing/input/data/vocab/vocab.txt'}\u001b[0m\n",
      "\u001b[34m2022-01-30 18:59:19,032 - inference.batch_predict - INFO - Running inference on file /opt/ml/processing/input/data/jsonlines/multinli_1.0_dev_matched.jsonl with output in /opt/ml/processing/output/multinli_1.0_dev_matched.jsonl.jsonl\u001b[0m\n",
      "\u001b[34m2022-01-30 18:59:19,032 - inference.batch_predict - INFO - Processing data file /opt/ml/processing/input/data/jsonlines/multinli_1.0_dev_matched.jsonl\u001b[0m\n",
      "\u001b[34m2022-01-30 18:59:23,968 - inference.batch_predict - INFO - Using args :{'datasetfactory': 'datasets.reverse_lang_mnli_dataset_factory.ReverseLangMnliDatasetFactory', 'traindir': '/opt/ml/input/data/train', 'valdir': '/opt/ml/input/data/val', 'testdir': None, 'modelfactory': 'models.bert_model_factory.BertModelFactory', 'pretrained_model_dir': '/opt/ml/input/data/PRETRAINED_MODEL', 'outdir': '/opt/ml/output/data', 'modeldir': '/opt/ml/model', 'checkpointdir': '/opt/ml/checkpoints/', 'checkpointfreq': '2', 'gradientaccumulationsteps': 8, 'learningrate': 1e-05, 'batch': 8, 'epochs': 1000, 'earlystoppingpatience': 250, 'numworkers': None, 'uselosseval': 0, 'log_level': 'INFO', 'commit_id': 'b3fafbd557bb8dbdb0a6f4eb5a50283d7527c47d', 'tokenisor_lower_case': '0', 'weight_decay': '0.01', 'pretrained_model': '/opt/ml/input/data/PRETRAINED_MODEL', 'vocab_file': '/opt/ml/processing/input/data/vocab/vocab.txt', 'tokenisor_data_dir': '/opt/ml/processing/input/data/vocab'}\u001b[0m\n",
      "\u001b[34m2022-01-30 18:59:24,486 - models.bert_model_factory - INFO - Retrieving model\u001b[0m\n",
      "\u001b[34m2022-01-30 18:59:26,391 - models.bert_model_factory - INFO - Retrieving key model_fine_tune with default 0, found 0\u001b[0m\n",
      "\u001b[34m2022-01-30 18:59:26,391 - models.bert_model_factory - INFO - Retrieving model complete\u001b[0m\n",
      "\u001b[34m2022-01-30 18:59:26,391 - dataset_builder - INFO - Retrieving Tokeniser\u001b[0m\n",
      "\u001b[34m2022-01-30 18:59:26,391 - models.bert_model_factory - INFO - Retrieving Tokeniser\u001b[0m\n",
      "\u001b[34m2022-01-30 18:59:26,391 - models.bert_model_factory - INFO - Retrieving key tokenisor_max_seq_len with default 512, found 512\u001b[0m\n",
      "\u001b[34m2022-01-30 18:59:26,391 - models.bert_model_factory - INFO - Retrieving key tokenisor_lower_case with default 0, found 0\u001b[0m\n",
      "\u001b[34m2022-01-30 18:59:26,391 - models.bert_model_factory - INFO - Retrieving key pretrained_model with default bert-base-cased, found /opt/ml/input/data/PRETRAINED_MODEL\u001b[0m\n",
      "\u001b[34m2022-01-30 18:59:26,391 - models.bert_model_factory - INFO - Retrieving key tokenisor_data_dir with default /opt/ml/input/data/PRETRAINED_MODEL, found /opt/ml/processing/input/data/vocab\u001b[0m\n",
      "\u001b[34m2022-01-30 18:59:26,873 - inference.predictor - INFO - Using device cuda:0\u001b[0m\n",
      "\u001b[34m[2022-01-30 18:59:30.011 ip-10-0-119-75.us-east-2.compute.internal:1 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-01-30 18:59:30.052 ip-10-0-119-75.us-east-2.compute.internal:1 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\u001b[0m\n",
      "\u001b[34m2022-01-30 19:03:22,179 - inference.predictor - INFO - Completed inference cuda:0\u001b[0m\n",
      "\u001b[34m2022-01-30 19:03:22,271 - dataset_builder - INFO - Retrieving Tokeniser\u001b[0m\n",
      "\u001b[34m2022-01-30 19:03:22,271 - datasets.reverse_lang_mnli_dataset_factory - INFO - Retrieving key vocab_file with default None, found /opt/ml/processing/input/data/vocab/vocab.txt\u001b[0m\n",
      "\u001b[34m2022-01-30 19:03:22,288 - dataset_builder - INFO - Retrieving Tokeniser\u001b[0m\n",
      "\u001b[34m2022-01-30 19:04:44,598 - inference.batch_predict - INFO - Records to write: 20000\u001b[0m\n",
      "\u001b[34m2022-01-30 19:04:44,598 - inference.batch_predict - INFO - Writing to file /opt/ml/processing/output/multinli_1.0_dev_matched.jsonl.jsonl\u001b[0m\n",
      "\n",
      "\u001b[34m2022-01-30 19:04:52,595 - inference.batch_predict - INFO - Completed file /opt/ml/processing/input/data/jsonlines/multinli_1.0_dev_matched.jsonl\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.network import NetworkConfig\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "script_processor = ScriptProcessor(image_uri=docker_repo,\n",
    "                                       command=[\"python\"],\n",
    "                                       env={'mode': 'python', 'PYTHONPATH':'/opt/ml/code'},\n",
    "                                       role=role,\n",
    "                                       instance_type=instance_type,\n",
    "                                       instance_count=instance_count,\n",
    "                                       max_runtime_in_seconds= 5 * 24 * 60 * 60,\n",
    "                                       volume_size_in_gb = 250,\n",
    "                                       network_config=NetworkConfig(enable_network_isolation=False),\n",
    "                                       base_job_name =\"bert-reverse-inference\"\n",
    "                                       )\n",
    "\n",
    "\n",
    "sm_local_input_models = \"/opt/ml/processing/input/data/models\"\n",
    "sm_local_input_data = \"/opt/ml/processing/input/data/jsonlines\"\n",
    "sm_local_input_vocab = \"/opt/ml/processing/input/data/vocab\"\n",
    "\n",
    "\n",
    "sm_local_output = \"/opt/ml/processing/output\"\n",
    "\n",
    "\n",
    "\n",
    "script_processor.run(\n",
    "        code='../src/inference/reverse_lang_mnli_batch_predict.py',\n",
    "\n",
    "        arguments=[\n",
    "            sm_local_input_data,\n",
    "            sm_local_input_models,\n",
    "            sm_local_output,\n",
    "            \"--tokenisor_data_dir\", sm_local_input_vocab,\n",
    "            \"--batch\", \"32\",\n",
    "            \"vocab_file\", f\"{sm_local_input_vocab}/vocab.txt\" \n",
    "        ],\n",
    "\n",
    "        inputs=[\n",
    "                ProcessingInput(\n",
    "                    source=s3_input_data,\n",
    "                    s3_data_type = s3_data_type,\n",
    "                    destination=sm_local_input_data,\n",
    "                    s3_data_distribution_type=\"FullyReplicated\"),\n",
    "\n",
    "                ProcessingInput(\n",
    "                        source=s3_model_path,\n",
    "                        destination=sm_local_input_models,\n",
    "                        s3_data_distribution_type=\"FullyReplicated\"),\n",
    "\n",
    "                ProcessingInput(\n",
    "                        source=s3_input_vocab,\n",
    "                        destination=sm_local_input_vocab,\n",
    "                        s3_data_distribution_type=\"FullyReplicated\")\n",
    "            ],\n",
    "\n",
    "\n",
    "        outputs=[ProcessingOutput(\n",
    "                source=sm_local_output, \n",
    "                destination=s3_output_predictions,\n",
    "                output_name='predictions')]\n",
    "    )\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
